{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "from transformers import AutoTokenizer\n",
    "from utils import load_prompts, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'logs/POEM_GPT2_BERT_output128_ND_IN_0.7/EPOCH400'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "output_min_length = 4\n",
    "output_max_length = 128\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "        \"min_length\": -1,\n",
    "        \"top_k\": 0.0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 1.0,\n",
    "        \"do_sample\": True,\n",
    "        \"repetition_penalty\": 1.0,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "gen_len = output_length_sampler()\n",
    "generation_kwargs[\"max_new_tokens\"] = gen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = random.choice(load_prompts(5))\n",
    "encoded_prompts = torch.tensor(tokenizer.encode(prompts)).long().to(device) \n",
    "response = model.generate(input_ids=encoded_prompts.unsqueeze(0), **generation_kwargs)\n",
    "decoded_response = tokenizer.decode(response.squeeze())\n",
    "eva = evaluation(decoded_response)\n",
    "print(prompts)\n",
    "print(decoded_response)\n",
    "print(eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('snlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fecc1a1012886715e5aa7030af6e07d463037e8bc0d1736033be3cbe0f25a56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
